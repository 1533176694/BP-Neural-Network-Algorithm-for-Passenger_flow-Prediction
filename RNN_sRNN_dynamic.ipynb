{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def onehotkey(X): \n",
    "    integer_encoded = LabelEncoder().fit_transform(X)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = OneHotEncoder(sparse=False).fit_transform(integer_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B: Xent Loss  0.5557508926896193\n",
      "F: Xent Loss  0.5759326267664994\n",
      "N: Xent Loss  0.6474466390346325\n"
     ]
    }
   ],
   "source": [
    "# compute the xent loss \n",
    "def ent(p):\n",
    "    if p>1 or p<0: return('Not Probability')\n",
    "    elif p==0 or p==1: return (0) \n",
    "    else: return -(p*np.log(p)+(1-p)*np.log(1-p))\n",
    "    \n",
    "# Data: (x4,x10)= four possibilities: Prob(y=1, x4, x10)\n",
    "# (1,1) -> p(y=1)=0.65\n",
    "# (0,1) -> p(y=1)=0.25\n",
    "# (1,0) -> p(y=1)=0.45\n",
    "# (0,0) -> p(y=1)=0.10 \n",
    "\n",
    "# The question is: does the machine has the capability to probe the details to this level? \n",
    "# If not capable of probing x10 dependence, then x10 is essentially a hidden variable \n",
    "#    whose influence needs to be summer over (marginalized), so we have\n",
    "#    p(y=1,x4) = sum_x10 p(y=1,x4,x10) = (0.65+0.45)/2 = 0.55 \n",
    "# If not capable of probing neither x4 or x10, we need to sum over both (as if both were hidden units)\n",
    "#    so we have p(y=1)= sum_x10,x4 p(y=1,x4,x10) = (0.65+0.25+0.40+0.10)/4 = 0.35 \n",
    "\n",
    "# Got both x10 and x4\n",
    "\n",
    "plist = [0.65,0.25,0.45,0.10]\n",
    "print (\"B: Xent Loss \", sum(ent(p) for p in plist)/len(plist))\n",
    "\n",
    "# Got only x4\n",
    "plist = [0.55, 0.175]\n",
    "print (\"F: Xent Loss \", sum(ent(p) for p in plist)/len(plist))\n",
    "\n",
    "# Got none\n",
    "plist = [(0.65+0.25+0.40+0.10)/4]\n",
    "print (\"N: Xent Loss \", sum(ent(p) for p in plist)/len(plist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "np.random.seed(2)\n",
    "tf.set_random_seed(2)\n",
    "\n",
    "# Configuration on Global Variables\n",
    "# 1. RNN Cell Configuration (normally num_neuron = state_size, but not necessary)\n",
    "#num_neuron = 10\n",
    "\n",
    "# 2. Recurrent Steps (Unfolding)\n",
    "num_steps = 25 # number of truncated backprop steps ('n' in the discussion above)\n",
    "pos_1=3\n",
    "pos_2=20\n",
    "\n",
    "# 3. Data Input/State/Output \n",
    "seq_size =   20000000\n",
    "#seq_size = 200000000\n",
    "state_size = 100\n",
    "num_classes = 2 \n",
    "\n",
    "# 4. Training (Mini-Batch, LearningRate, Dropout, ...)\n",
    "batch_size = 400\n",
    "learning_rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(seq_size, batch_size, num_steps): \n",
    "    X = np.random.choice([0,1], p=[0.5,0.5], size=seq_size)   \n",
    "    pos1=4\n",
    "    pos2=40\n",
    "    plist=[0.65, 0.45, 0.25, 0.10]\n",
    "    p2=np.zeros((2, 2))\n",
    "    p2[1,1]=plist[0]\n",
    "    p2[1,0]=plist[1]\n",
    "    p2[0,1]=plist[2]\n",
    "    p2[0,0]=plist[3]\n",
    "\n",
    "    X = np.random.choice([0,1], p = [0.5, 0.5], size = seq_size)\n",
    "    Prob = p2[np.roll(X,pos1), np.roll(X,pos2)]\n",
    "    Y = (np.random.rand(len(X)) < Prob).astype(int)\n",
    "    \n",
    "    epoch_size = seq_size // (batch_size*num_steps)\n",
    "    \n",
    "    X.resize(batch_size, epoch_size, num_steps)\n",
    "    Y.resize(batch_size, epoch_size, num_steps)\n",
    "    \n",
    "    for i in range(epoch_size):\n",
    "        yield (X[:,i,:],Y[:,i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_inputs (400, 25, 2)\n",
      "WARNING:tensorflow:From <ipython-input-7-3bf977cce50d>:14: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-7-3bf977cce50d>:15: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "rnn_output (400, 25, 100)\n",
      "final_state (400, 100)\n",
      "logits (400, 25, 2)\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Input and Output_labeling (turn everything into a list for handling)\n",
    "# num_class is assumed to be the same for input and output (not necessary)\n",
    "# run_inputs list of num_steps tensors with shape [batch_size, num_classes]\n",
    "# initial state \n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "rnn_inputs = tf.one_hot(x, num_classes)\n",
    "print(\"rnn_inputs\", rnn_inputs.get_shape())\n",
    "\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(state_size)\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state, dtype=\"float32\")\n",
    "\n",
    "print(\"rnn_output\", rnn_outputs.get_shape())\n",
    "print(\"final_state\", final_state.get_shape())\n",
    "\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "\n",
    "logits = tf.reshape(\n",
    "            tf.matmul(tf.reshape(rnn_outputs, [-1, state_size]), W) + b,\n",
    "            [batch_size, num_steps, num_classes])\n",
    "print(\"logits\", logits.get_shape())\n",
    "\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step & Loss:  200 1.3797454246878624\n",
      "Step & Loss:  400 0.5942327061295509\n",
      "Step & Loss:  600 0.5803773182630539\n",
      "Step & Loss:  800 0.5766353461146355\n",
      "Step & Loss:  1000 0.576211154460907\n",
      "Step & Loss:  1200 0.5763591688871383\n",
      "Step & Loss:  1400 0.5756925541162491\n",
      "Step & Loss:  1600 0.5763954567909241\n",
      "Step & Loss:  1800 0.576006421148777\n",
      "Num of Unfolding (num_steps)  25\n",
      "Num of Neurons in RNN Cell (state_size)  100\n",
      "Sequence Length(seq_size)  20000000\n",
      "Batch,Steps,Epoch  400 25 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x104725b38>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training the network \n",
    "def train_network(seq_size, num_steps, state_size, printout=10):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "               \n",
    "        training_loss = 0\n",
    "        training_state = np.zeros((batch_size, state_size))\n",
    "        step = 0\n",
    "\n",
    "        for (X, Y) in gen_batch(seq_size, batch_size, num_steps):\n",
    "            training_loss_, training_state, _ = \\\n",
    "                sess.run([total_loss, final_state, train_step],\n",
    "                              feed_dict={x:X, y:Y, init_state:training_state})\n",
    "            training_loss += training_loss_\n",
    "            if step % printout == 0 and step > 0:\n",
    "                print(\"Step & Loss: \", step, training_loss/printout)\n",
    "                training_losses.append(training_loss/printout)\n",
    "                training_loss = 0\n",
    "            step +=1\n",
    "                \n",
    "    return training_losses\n",
    "\n",
    "training_losses = train_network(seq_size,num_steps,state_size, printout=200)\n",
    "print('Num of Unfolding (num_steps) ', num_steps)\n",
    "print('Num of Neurons in RNN Cell (state_size) ', state_size)\n",
    "print('Sequence Length(seq_size) ', seq_size)\n",
    "print('Batch,Steps,Epoch ', batch_size, num_steps, seq_size//(batch_size*num_steps))\n",
    "plt.ylim(0.45, 0.68)\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3797454246878624,\n",
       " 0.5942327061295509,\n",
       " 0.5803773182630539,\n",
       " 0.5766353461146355,\n",
       " 0.576211154460907,\n",
       " 0.5763591688871383,\n",
       " 0.5756925541162491,\n",
       " 0.5763954567909241,\n",
       " 0.576006421148777]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "11px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
